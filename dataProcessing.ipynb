{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Liabraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for the Excel file stored in Google Drive\n",
    "file_path = 'DataSet_EU_3k_5k.xlsx'\n",
    "\n",
    "# Use pandas to read the Excel file located at the specified file path\n",
    "data = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power_1</th>\n",
       "      <th>Power_2</th>\n",
       "      <th>Power_3</th>\n",
       "      <th>Power_4</th>\n",
       "      <th>Power_5</th>\n",
       "      <th>Power_6</th>\n",
       "      <th>Power_7</th>\n",
       "      <th>Power_8</th>\n",
       "      <th>Power_9</th>\n",
       "      <th>Power_10</th>\n",
       "      <th>...</th>\n",
       "      <th>GSNR_69</th>\n",
       "      <th>GSNR_70</th>\n",
       "      <th>GSNR_71</th>\n",
       "      <th>GSNR_72</th>\n",
       "      <th>GSNR_73</th>\n",
       "      <th>GSNR_74</th>\n",
       "      <th>GSNR_75</th>\n",
       "      <th>GSNR_76</th>\n",
       "      <th>No. Spans</th>\n",
       "      <th>Total Distance(m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.061284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.045789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>690608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.560867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.544975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>690608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.991977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.512399</td>\n",
       "      <td>83.114113</td>\n",
       "      <td>8</td>\n",
       "      <td>690608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.409583</td>\n",
       "      <td>73.664915</td>\n",
       "      <td>74.651700</td>\n",
       "      <td>79.071217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>690608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.299438</td>\n",
       "      <td>74.910765</td>\n",
       "      <td>72.030907</td>\n",
       "      <td>73.790264</td>\n",
       "      <td>81.190439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>690608.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 382 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Power_1   Power_2   Power_3   Power_4   Power_5   Power_6   Power_7  \\\n",
       "0  0.000000  0.000000  0.000007  0.000007  0.000007  0.000000  0.000007   \n",
       "1  0.000000  0.000007  0.000000  0.000007  0.000000  0.000007  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000007  0.000000  0.000000  0.000000   \n",
       "3  0.000007  0.000007  0.000007  0.000007  0.000007  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000007  0.000000  0.000007  0.000000  0.000000   \n",
       "\n",
       "   Power_8   Power_9  Power_10  ...    GSNR_69    GSNR_70    GSNR_71  \\\n",
       "0      0.0  0.000007       0.0  ...  90.061284   0.000000   0.000000   \n",
       "1      0.0  0.000000       0.0  ...   0.000000  92.560867   0.000000   \n",
       "2      0.0  0.000007       0.0  ...   0.000000   0.000000  90.991977   \n",
       "3      0.0  0.000007       0.0  ...  76.409583  73.664915  74.651700   \n",
       "4      0.0  0.000007       0.0  ...   0.000000   0.000000  78.299438   \n",
       "\n",
       "     GSNR_72    GSNR_73    GSNR_74    GSNR_75    GSNR_76  No. Spans  \\\n",
       "0   0.000000   0.000000  95.045789   0.000000   0.000000          8   \n",
       "1   0.000000  89.544975   0.000000   0.000000   0.000000          8   \n",
       "2   0.000000   0.000000   0.000000  85.512399  83.114113          8   \n",
       "3  79.071217   0.000000   0.000000   0.000000   0.000000          8   \n",
       "4  74.910765  72.030907  73.790264  81.190439   0.000000          8   \n",
       "\n",
       "   Total Distance(m)  \n",
       "0           690608.0  \n",
       "1           690608.0  \n",
       "2           690608.0  \n",
       "3           690608.0  \n",
       "4           690608.0  \n",
       "\n",
       "[5 rows x 382 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataframe to get an overview of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the attribute columns and the target variable\n",
    "attribute_columns = [f'Power_{i}' for i in range(1, 77)] + [f'ASE_{i}' for i in range(1, 77)] + [f'NLI_{i}' for i in range(1, 77)]+ ['No. Spans'] + ['Total Distance(m)']\n",
    "\n",
    "# Label\n",
    "target_column = 'GSNR_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax Normalized Data:\n",
      "0    0.000000\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "3    0.076798\n",
      "4    0.000000\n",
      "Name: Power_1, dtype: float64 0    0.075117\n",
      "1    0.073203\n",
      "2    0.073788\n",
      "3    0.000062\n",
      "4    0.071547\n",
      "Name: ASE_1, dtype: float64 0    0.000000\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "3    0.017928\n",
      "4    0.000000\n",
      "Name: NLI_1, dtype: float64 0    0.037037\n",
      "1    0.037037\n",
      "2    0.037037\n",
      "3    0.037037\n",
      "4    0.037037\n",
      "Name: No. Spans, dtype: float64 0    0.008849\n",
      "1    0.008849\n",
      "2    0.008849\n",
      "3    0.008849\n",
      "4    0.008849\n",
      "Name: Total Distance(m), dtype: float64\n",
      "    GSNR_1\n",
      "0  0.00000\n",
      "1  0.00000\n",
      "2  0.00000\n",
      "3  0.79791\n",
      "4  0.00000\n"
     ]
    }
   ],
   "source": [
    "# MinMax Normalization\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the attribute columns using MinMaxScaler and convert the result back to a DataFrame\n",
    "x = scaler.fit_transform(data[attribute_columns])\n",
    "x = pd.DataFrame(x, columns=attribute_columns)\n",
    "\n",
    "# Extract the target variable values and reshape them for normalization\n",
    "y = data[target_column].values.reshape(-1, 1)\n",
    "# Normalize the target variable using MinMaxScaler and convert the result back to a DataFrame\n",
    "y = scaler.fit_transform(y)\n",
    "y = pd.DataFrame(y, columns=[target_column])\n",
    "\n",
    "# Display the first few rows of the normalized data for selected columns\n",
    "print(\"MinMax Normalized Data:\")\n",
    "print(x['Power_1'].head(), x['ASE_1'].head(), x['NLI_1'].head(), x['No. Spans'].head(), x['Total Distance(m)'].head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized data with equal path distribution in train and test data :\n",
      "\n",
      "Train data shape: (15000, 230)\n",
      "Test data shape: (3000, 230)\n",
      "Train labels shape: (15000,)\n",
      "Test labels shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "# Define the function to split data according to the specified pattern\n",
    "def custom_train_test_split(data, labels, samples_per_block=3000, train_samples_per_block=2500, test_samples_per_block=500):\n",
    "    # Initialize lists to hold the training and testing data and labels\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    # Determine the total number of samples in the data\n",
    "    total_samples = len(data)\n",
    "\n",
    "    # Loop over the data in blocks of the specified size (samples_per_block)\n",
    "    for start in range(0, total_samples, samples_per_block):\n",
    "        # Define the end of the current block\n",
    "        end = start + samples_per_block\n",
    "        # Define the end of the training samples within the current block\n",
    "        train_end = start + train_samples_per_block\n",
    "\n",
    "        # Adjust train_end and end if they exceed the total number of samples\n",
    "        if train_end > total_samples:\n",
    "            train_end = total_samples\n",
    "        if end > total_samples:\n",
    "            end = total_samples\n",
    "\n",
    "        # Append the training and testing data and labels for the current block to the respective lists\n",
    "        train_data.append(data[start:train_end])\n",
    "        test_data.append(data[train_end:end])\n",
    "        train_labels.append(labels[start:train_end])\n",
    "        test_labels.append(labels[train_end:end])\n",
    "\n",
    "    # Concatenate the lists into DataFrames and reset the index\n",
    "    train_data = pd.concat(train_data).reset_index(drop=True)\n",
    "    test_data = pd.concat(test_data).reset_index(drop=True)\n",
    "    train_labels = pd.concat(train_labels).reset_index(drop=True)\n",
    "    test_labels = pd.concat(test_labels).reset_index(drop=True)\n",
    "\n",
    "    # Return the training and testing data and labels\n",
    "    return train_data, test_data, train_labels, test_labels\n",
    "\n",
    "# Create a list of attribute columns excluding those that start with 'frequency'\n",
    "attribute_columns_without_frequency = [col for col in attribute_columns if not col.startswith('frequency')]\n",
    "\n",
    "# Assuming 'x' and 'y' are your DataFrames for MinMax normalized data\n",
    "# Perform the custom train-test split on the normalized data\n",
    "X_train, X_test, Y_train, Y_test = custom_train_test_split(x[attribute_columns_without_frequency], y[target_column])\n",
    "\n",
    "# Display shapes to verify the split\n",
    "print(\"Normalized data with equal path distribution in train and test data :\\n\")\n",
    "print(\"Train data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Train labels shape:\", Y_train.shape)\n",
    "print(\"Test labels shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the data to a file\n",
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump((X_train, Y_train, X_test, Y_test), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
